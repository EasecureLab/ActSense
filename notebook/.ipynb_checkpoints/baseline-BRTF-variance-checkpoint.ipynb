{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"../code/\")\n",
    "import BRCP_TC as VBTF\n",
    "from basic import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the data and split it into train and test set\n",
    "tensor, homeids = get_tensor(2015, 'artificial')\n",
    "train, test, tr_ids, tt_ids = get_train_test(tensor, homeids, fold_num=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel_function(mu_1, mu_2, sigma_1, sigma_2):\n",
    "#     mu_1 = mu[idx1]\n",
    "#     mu_2 = mu[idx2]\n",
    "#     sigma_1 = np.diag(np.diag(sigma[idx1]))\n",
    "#     sigma_2 = np.diag(np.diag(sigma[idx2]))\n",
    "    \n",
    "    p1 = np.trace(np.linalg.inv(sigma_2) @ sigma_1) \n",
    "    p2 = (mu_2 - mu_1).T @ np.linalg.inv(sigma_2) @ (mu_2 - mu_1) \n",
    "    p3 = np.log(np.linalg.det(sigma_1) / np.linalg.det(sigma_2))\n",
    "    DKL_1 = 0.5 * (p1 + p2 + p3)\n",
    "    \n",
    "    p1 = np.trace(np.linalg.inv(sigma_1) @ sigma_2) \n",
    "    p2 = (mu_1 - mu_2).T @ np.linalg.inv(sigma_1) @ (mu_1 - mu_2) \n",
    "    p3 = np.log(np.linalg.det(sigma_2) / np.linalg.det(sigma_1))\n",
    "    DKL_2 = 0.5 * (p1 + p2 + p3)\n",
    "    \n",
    "    return np.exp((DKL_1  + DKL_2)/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_variance(idx1, idx2, mu_1, mu_2, sigma_1, sigma_2):\n",
    "    mean_1 = mu_1[idx1]\n",
    "    mean_2 = mu_2[idx2]\n",
    "    var_1 = sigma_1[:, :, idx1]\n",
    "    var_2 = sigma_2[:, :, idx2]\n",
    "    \n",
    "    p1 = np.diag(var_1).T @ (mean_2 ** 2) + np.diag(var_2).T @ (mean_1 ** 2) + np.diag(var_1).T @ (np.diag(var_2))\n",
    "    \n",
    "    p2 = 0\n",
    "    for i in range(len(mean_1) - 1):\n",
    "        for j in range(i, len(mean_1)):\n",
    "            p2 += var_1[i, j] * mean_2[i] * mean_2[j] + var_2[i, j]* mean_1[i] * mean_1[j] + var_1[i, j] * var_2[i, j]\n",
    "    \n",
    "    return p1 + 2 * p2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prepare for the trainin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_tensor = np.concatenate([train, test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### when t = 0, only the aggregate is available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 7 12\n",
      "0 0.0027107374825009038\n"
     ]
    }
   ],
   "source": [
    "mask_tensor = np.zeros(tensor.shape, dtype='int')\n",
    "mask_tensor[:, 0, 0] = 1\n",
    "Z, ZSigma = VBTF.BTCP_TC(tensor, mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00780079, 0.        , 0.        ],\n",
       "       [0.        , 0.00246395, 0.        ],\n",
       "       [0.        , 0.        , 0.00189221]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diag(np.diag(ZSigma[0][:, :, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### get the variance of each cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "variance = np.zeros((train.shape[0], train.shape[1]))\n",
    "\n",
    "for i in range(train.shape[0]):\n",
    "    for j in range(train.shape[1]):\n",
    "        variance[i, j] = get_variance(i, j, Z[0], Z[1], ZSigma[0], ZSigma[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def largest_indices(ary, n):\n",
    "    \"\"\"Returns the n largest indices from a numpy array.\"\"\"\n",
    "    flat = ary.flatten()\n",
    "    indices = np.argpartition(flat, -n)[-n:]\n",
    "    indices = indices[np.argsort(-flat[indices])]\n",
    "    return np.unravel_index(indices, ary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mask_matrix = np.ones((tensor.shape[0], tensor.shape[1]))\n",
    "mask_matrix[:, 0] = 0\n",
    "mask_tensor = np.zeros((new_tensor.shape), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'BTCP_TC' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-f18bf286e3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmask_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_matrix\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# get the factors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mZ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mZSigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBTCP_TC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# calculate the variance of each prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'BTCP_TC' is not defined"
     ]
    }
   ],
   "source": [
    "for t in range(1):\n",
    "\n",
    "    # update mask_tensor\n",
    "    mask_tensor[:, :, t] = -(mask_matrix - 1)\n",
    "    # get the factors\n",
    "    Z, ZSigma = VBTF.BTCP_TC(tensor, mask_tensor)\n",
    "\n",
    "    # calculate the variance of each prediction\n",
    "    variance = np.zeros((train.shape[0], train.shape[1]))\n",
    "    for i in range(R - 1):\n",
    "        for j in range(i, R):\n",
    "            variance[i, j] = get_variance(i, j, Z[0], Z[1], ZSigma[0], ZSigma[1])\n",
    "\n",
    "    # get the home and appliance id\n",
    "    variance = variance * mask_matrix[:(train.shape[0]), :]\n",
    "    print(variance)\n",
    "    hid, aid = largest_indices(variance, k)\n",
    "\n",
    "    # update mask_matrix\n",
    "    mask_matrix[hid, aid] = 0\n",
    "\n",
    "    print(\"Iteration {}: {}-{}, {}-{}, {}-{}, {}-{}, {}-{}\".format(t, hid[0], aid[0], hid[1], aid[1], hid[2], aid[2], hid[3], aid[3], hid[4], aid[4]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_matrix[hid, aid] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tensor[:, 0, 1] = 1\n",
    "mask_tensor[:(train.shape[0]), :, 1] = -(mask_matrix - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the next month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93 7 12\n",
      "0 5.20777169693172\n"
     ]
    }
   ],
   "source": [
    "Z, ZSigma = VBTF.BTCP_TC(tensor, mask_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5770.832088591563"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = np.einsum(\"Hr, Ar, Sr -> HAS\", h, a, t)\n",
    "mean_squared_error(tensor.flatten(), pred.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 201.08673096,  290.8949585 ,  304.30499268,  350.92425537,\n",
       "        339.30471802,  206.72924805,  361.14483643,  531.29327393,\n",
       "        270.12286377,  160.86392212,  472.18338013,  195.35244751,\n",
       "        220.07647705,  276.45025635,  200.59249878,  112.43449402,\n",
       "        231.83633423,  335.33242798,  210.56591797,  280.79748535,\n",
       "        377.06060791, 1354.52929688,  192.30148315,  211.97564697,\n",
       "        166.0861969 ,  389.81521606,  406.40332031,  114.78800964,\n",
       "        283.78601074,  431.5791626 ,  178.95809937,  109.14002991,\n",
       "        226.00462341,  409.70123291,  198.72473145,  581.5927124 ,\n",
       "        252.67962646,  219.1631012 ,  276.84185791,  512.79931641,\n",
       "        166.78622437,  167.29231262,  160.66467285,  230.3039856 ,\n",
       "        185.42828369,  330.92483521,  149.27023315,  188.49328613,\n",
       "        159.45170593,  146.09744263,  209.31143188,  101.3601532 ,\n",
       "        220.15386963,  266.87792969,  267.2164917 ,  214.62791443,\n",
       "        214.92733765,  281.69244385,  233.84706116,  193.69644165,\n",
       "        179.38529968,  157.58746338,  269.43792725,  494.63592529,\n",
       "        323.68582153,  568.59088135,  331.91882324,   95.5956955 ,\n",
       "        394.14263916,  802.40148926,  249.46873474,  166.71749878,\n",
       "        395.34539795,  200.15643311,  938.46258545,  152.6020813 ,\n",
       "        159.6572876 ,  493.83865356,  291.51879883,  199.94967651,\n",
       "        209.33026123,  385.90823364,  326.30352783,  186.36213684,\n",
       "        115.45777893,  304.53509521,  208.18148804,  160.39294434,\n",
       "        225.78704834,  235.41845703,  229.73126221,  136.23526001,\n",
       "        148.24227905])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor[:, 0, 0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
